{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl \"https://raw.githubusercontent.com/sonlam1102/vihsd/refs/heads/main/data/vihsd.zip\" --output vihsd.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip \"./DePrBViHO/Dataset/ViHSD/vihsd.zip\" -d \"./DePrBViHO/Dataset/ViHSD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and other stuff thing(do not care)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SnuQNrQ5Cxi_",
    "outputId": "bce3c929-1567-465a-f296-ccfc8346734d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import oneccl_bindings_for_pytorch\n",
    "\n",
    "random.seed(1963)\n",
    "np.random.seed(1963)\n",
    "torch.manual_seed(1963)\n",
    "device = torch.device('xpu' if torch.xpu.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EC3f9k0DvrJr"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('./DePrBViHO/Dataset/ViHSD/train.csv')\n",
    "dev = pd.read_csv('./DePrBViHO/Dataset/ViHSD/dev.csv')\n",
    "test = pd.read_csv('./DePrBViHO/Dataset/ViHSD/test.csv')\n",
    "\n",
    "\n",
    "train['free_text'] = train['free_text'].astype(str)\n",
    "X_train = train['free_text']\n",
    "y_train = train[\"label_id\"]\n",
    "\n",
    "dev['free_text'] = dev['free_text'].astype(str)\n",
    "X_valid = dev['free_text']\n",
    "y_valid = dev['label_id']\n",
    "\n",
    "test['free_text'] = test['free_text'].astype(str)\n",
    "X_test = test['free_text']\n",
    "y_test = test['label_id']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "gI8SPqPcA8BS",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base-v2', clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import demoji\n",
    "from underthesea import word_tokenize\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import os \n",
    "\n",
    "def preprocess(text):\n",
    "    text = demoji.replace(text, \"\")\n",
    "    text = word_tokenize(text, format=\"text\")\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'\\s*([.,!?;])\\s*', r'\\1 ', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text).strip()\n",
    "    text = re.sub(r'\\s([.,!?;])', r'\\1', text)\n",
    "    text = re.sub(r'([.,!?;])\\s*', r'\\1 ', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def pre_process_features(X, batch_size=5000, index_file=\"processed_batches.txt\", folder = \"./Savedata_Train/\"):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    num_batches = len(X) // batch_size + (1 if len(X) % batch_size != 0 else 0)\n",
    "    \n",
    "    # Mở file để ghi tên các batch\n",
    "    with open(index_file, 'w') as index_f:\n",
    "        with Pool(cpu_count()) as p:\n",
    "            for i in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
    "                start_idx = i * batch_size\n",
    "                end_idx = (i + 1) * batch_size\n",
    "                batch_X = X[start_idx:end_idx]\n",
    "                processed_batch_X = list(p.imap(preprocess, batch_X))\n",
    "\n",
    "                # Lưu phần nhỏ đã xử lý vào tệp tạm thời\n",
    "                batch_file = f\"{folder}batch_{i}.pkl\"\n",
    "                with open(batch_file, 'wb') as f:\n",
    "                    pickle.dump(processed_batch_X, f)\n",
    "                # Ghi tên file vào index file\n",
    "                index_f.write(f\"{batch_file}\\n\")\n",
    "\n",
    "            p.close()\n",
    "            p.join()\n",
    "def pre_process_features(X, batch_size=5000, index_file=\"processed_batches.txt\", folder = \"./Savedata/\"):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    num_batches = len(X) // batch_size + (1 if len(X) % batch_size != 0 else 0)\n",
    "    \n",
    "    # Mở file để ghi tên các batch\n",
    "    with open(folder + index_file, 'w') as index_f:\n",
    "        with Pool(cpu_count()) as p:\n",
    "            for i in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
    "                start_idx = i * batch_size\n",
    "                end_idx = (i + 1) * batch_size\n",
    "                batch_X = X[start_idx:end_idx]\n",
    "                processed_batch_X = list(p.imap(preprocess, batch_X))\n",
    "\n",
    "                # Lưu phần nhỏ đã xử lý vào tệp tạm thời\n",
    "                batch_file = f\"batch_{i}.pkl\"\n",
    "                with open(folder + batch_file, 'wb') as f:\n",
    "                    pickle.dump(processed_batch_X, f)\n",
    "                # Ghi tên file vào index file\n",
    "                index_f.write(f\"{batch_file}\\n\")\n",
    "\n",
    "            p.close()\n",
    "            p.join()\n",
    "pre_process_features(X_train,  folder = \"./Savedata_Train/\")\n",
    "pre_process_features(X_valid,  folder = \"./Savedata_Vaild/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_processed_data(index_file=\"processed_batches.txt\", folder = \"./Savedata/\"):\n",
    "    processed_X = []\n",
    "    with open(folder + index_file, 'r') as index_f:\n",
    "        for batch_file in index_f:\n",
    "            batch_file = folder + batch_file.strip()\n",
    "            with open(batch_file, 'rb') as f:\n",
    "                batch_X = pickle.load(f)\n",
    "                processed_X.extend(batch_X)\n",
    "            # Có thể xóa file sau khi tải nếu cần\n",
    "            # os.remove(batch_file)\n",
    "    return processed_X\n",
    "X_train = load_processed_data(folder=\"./Savedata_Train/\")\n",
    "X_valid = load_processed_data(folder=\"./Savedata_Vaild/\")\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "encoded_labels = le.transform(y_train)\n",
    "encoded_test_labels = le.transform(y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def encoder_generator(sentences, labels):\n",
    "    sent_index = []\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for index, sent in tqdm(enumerate(sentences), total=len(sentences), desc=\"Encoding Sentences\"):\n",
    "        sent_index.append(index)\n",
    "\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sent,\n",
    "            add_special_tokens=True,\n",
    "            max_length=20,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "    sent_index = torch.tensor(sent_index)\n",
    "\n",
    "    return sent_index, input_ids, attention_masks, labels\n",
    "\n",
    "train_sent_index, train_input_ids, train_attention_masks, train_encoded_label_tensors = encoder_generator(X_train, encoded_labels)\n",
    "dev_sent_index, dev_input_ids, dev_attention_masks, dev_encoded_label_tensors = encoder_generator(X_valid, encoded_test_labels)\n",
    "\n",
    "print('Original: ', X_train[0])\n",
    "print('Token IDs:', train_input_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training data to a file\n",
    "with open('train_data.pkl', 'wb') as train_file:\n",
    "    pickle.dump((train_sent_index, train_input_ids, train_attention_masks, train_encoded_label_tensors), train_file)\n",
    "\n",
    "# Save the validation data to another file\n",
    "with open('dev_data.pkl', 'wb') as dev_file:\n",
    "    pickle.dump((dev_sent_index, dev_input_ids, dev_attention_masks, dev_encoded_label_tensors), dev_file)\n",
    "\n",
    "print(\"Data saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the training data\n",
    "with open('train_data.pkl', 'rb') as train_file:\n",
    "    train_sent_index, train_input_ids, train_attention_masks, train_encoded_label_tensors = pickle.load(train_file)\n",
    "\n",
    "# Load the validation data\n",
    "with open('dev_data.pkl', 'rb') as dev_file:\n",
    "    dev_sent_index, dev_input_ids, dev_attention_masks, dev_encoded_label_tensors = pickle.load(dev_file)\n",
    "\n",
    "print(\"Data loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_BYbqZ7NMMWw",
    "outputId": "e731f62e-ccb4-4f92-cde7-631331e6b309"
   },
   "outputs": [],
   "source": [
    "# Connvert train, dev input by using TensorDataset\n",
    "\n",
    "from torch.utils.data import TensorDataset,random_split\n",
    "\n",
    "train_dataset = TensorDataset(train_input_ids,train_attention_masks,train_encoded_label_tensors)\n",
    "dev_dataset = TensorDataset(dev_input_ids,dev_attention_masks,dev_encoded_label_tensors)\n",
    "\n",
    "print('train data samples is {}'.format(len(train_dataset)))\n",
    "print(\"valid data samples is {}\".format(len(dev_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Em9Q1v0BMZZX"
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader,RandomSampler,SequentialSampler\n",
    "\n",
    "bs=128\n",
    "\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset,\n",
    "                              sampler=RandomSampler(train_dataset),\n",
    "                              batch_size=bs)\n",
    "valid_data_loader = DataLoader(dev_dataset,\n",
    "                              sampler=RandomSampler(dev_dataset),\n",
    "                              batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q44-J-QWMgKQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Linear layer to process the input embedding\n",
    "        self.fc_input = nn.Linear(embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Convolutional layers with different filter sizes\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embedding_dim,\n",
    "                      out_channels=n_filters,\n",
    "                      kernel_size=fs)\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        \n",
    "        # Fully connected layer to produce the final output\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, encoded):\n",
    "        \"\"\"\n",
    "        Forward pass of the CNN model.\n",
    "        \n",
    "        :param encoded: Tensor of shape [batch size, sentence length, embedding dimension]\n",
    "        :return: Tensor of shape [batch size, output dimension]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply the fully connected layer to the input\n",
    "        embedded = self.fc_input(encoded)  # [batch size, sent len, emb dim]\n",
    "        \n",
    "        # Rearrange dimensions for Conv1d layer (expected input shape: [batch size, emb dim, sent len])\n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        \n",
    "        # Apply each convolutional layer and ReLU activation, then max-pool over the output\n",
    "        pooled_outputs = []\n",
    "        for conv in self.convs:\n",
    "            conved = F.relu(conv(embedded))  # [batch size, n_filters, sent len - kernel_size + 1]\n",
    "            pooled = F.max_pool1d(conved, conved.shape[2]).squeeze(2)  # [batch size, n_filters]\n",
    "            pooled_outputs.append(pooled)\n",
    "        \n",
    "        # Concatenate all pooled outputs\n",
    "        cat = self.dropout(torch.cat(pooled_outputs, dim=1))  # [batch size, n_filters * len(filter_sizes)]\n",
    "        \n",
    "        # Pass through the final fully connected layer to get output\n",
    "        result = self.fc(cat)  # [batch size, output_dim]\n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTo_bpEeMqgr"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 768\n",
    "N_FILTERS = 32\n",
    "FILTER_SIZES = [1,2,3,5]\n",
    "OUTPUT_DIM = len(le.classes_)\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = tokenizer.pad_token_id\n",
    "\n",
    "cnn = CNN(EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "1697209912864e0884c53bc70eac7929",
      "6c79c954408749abb907934a56b6995f",
      "4b4c93c9fa0e42d0bfe5edf37716e5be",
      "b0be66a7a999436292c18cab3eb88d9f",
      "196ac666266f47b193ca577e4a5a4027",
      "a120123a22d946d7ba07ce88964ba891",
      "bff2bc27692e4434bb2418f26da44793",
      "eeaeeab00bdc40dbad28ab45da8ef293",
      "4078451a1ccc49e7a7cb0e3edcf8c7af",
      "32c38b57c2d644ec895fd3bce126dd2c",
      "51f9d11c02814521a70b6a2a3e1c5cf6"
     ]
    },
    "id": "sQiHRn2zMdIJ",
    "outputId": "be0e60d8-4548-4a26-b162-b1b94a7be545"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "phoBert = AutoModel.from_pretrained('vinai/phobert-base-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITmi7WZDMsl6",
    "outputId": "e7ea6491-8d9c-4821-c7f8-c7fa0b1da51e"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model_prameters = list(phoBert.parameters())+list(cnn.parameters())\n",
    "\n",
    "optimizer = optim.AdamW(model_prameters,lr=2e-5,eps=1e-8, weight_decay=1e-5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoBert = phoBert.to(device)\n",
    "cnn = cnn.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "cnn.train()\n",
    "phoBert.train()\n",
    "cnn, optimizer = ipex.optimize(cnn, optimizer=optimizer)\n",
    "phoBert, optimizer = ipex.optimize(phoBert, optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oyp8HhAxMvQH"
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy per batch during train\n",
    "\n",
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]]).xpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrVcBEVoMxov"
   },
   "outputs": [],
   "source": [
    "# Def for training\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train():\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    phoBert.train()\n",
    "    cnn.train()                                                                                                                                                                            \n",
    "\n",
    "    for batch in tqdm(train_data_loader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        embedded = phoBert(b_input_ids,b_input_mask)[0]\n",
    "\n",
    "        predictions = cnn(embedded)\n",
    "\n",
    "        loss = criterion(predictions, b_labels)\n",
    "\n",
    "        acc = categorical_accuracy(predictions, b_labels)\n",
    "\n",
    "        loss.requires_grad = True\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(train_data_loader), epoch_acc / len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTQGFfnFMz-d"
   },
   "outputs": [],
   "source": [
    "# Class for predict label\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def predictions_labels(preds,labels):\n",
    "    pred = np.argmax(preds,axis=1).flatten()\n",
    "    label = labels.flatten()\n",
    "    return pred,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_4Y1RhlM17e"
   },
   "outputs": [],
   "source": [
    "# Evaluate loss, acc  and f1-macro\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score,f1_score,recall_score\n",
    "\n",
    "def eval():\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    total_predictions = []\n",
    "    total_true = []\n",
    "\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "\n",
    "    phoBert.eval()\n",
    "    cnn.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in tqdm(valid_data_loader):\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            embedded = phoBert(b_input_ids,b_input_mask)[0]\n",
    "            predictions = cnn(embedded)\n",
    "\n",
    "            loss = criterion(predictions, b_labels)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            predictions = predictions.detach().cpu().numpy()\n",
    "\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            pred,true = predictions_labels(predictions,label_ids)\n",
    "\n",
    "            all_pred_labels.extend(pred)\n",
    "            all_true_labels.extend(true)\n",
    "\n",
    "    print(classification_report(all_pred_labels,all_true_labels))\n",
    "    avg_val_accuracy = accuracy_score(all_pred_labels,all_true_labels)\n",
    "    macro_f1_score = f1_score(all_pred_labels,all_true_labels,average='macro')\n",
    "\n",
    "    avg_val_loss = epoch_loss/len(valid_data_loader)\n",
    "\n",
    "    print(\"accuracy = {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    return avg_val_loss,avg_val_accuracy,macro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICyenO-tM35S"
   },
   "outputs": [],
   "source": [
    "# Time for training\n",
    "\n",
    "import time\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OrAOzamNC0e",
    "outputId": "295c857d-1d82-4c45-8798-c2e59d195b87"
   },
   "outputs": [],
   "source": [
    "# Set device and gpu\n",
    "\n",
    "n_gpu = torch.xpu.device_count()\n",
    "torch.xpu.get_device_name(0)\n",
    "\n",
    "phoBert.xpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbJBkClEkam2"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZfHllZjgM5uw",
    "outputId": "7b481868-a527-4bc2-8af4-246cd6d2670e"
   },
   "outputs": [],
   "source": [
    "\n",
    "best_macro_f1 = float('0')\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss,train_acc = train()\n",
    "    valid_loss,valid_acc,macro_f1 = eval()\n",
    "    end_time = time.time()\n",
    "\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if macro_f1 > best_macro_f1:\n",
    "        best_macro_f1 = macro_f1\n",
    "        torch.save(phoBert,'./phobert_cnn_model_part1_'+'task2a_2.pt')\n",
    "        torch.save(cnn,'./phobert_cnn_model_part2_'+'task2a_2.pt')\n",
    "        print(\"model saved\")\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. acc: {valid_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. F1: {macro_f1*100:.2f}%')\n",
    "    print('=============Epoch Ended==============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KyQlcVfnCWHw"
   },
   "outputs": [],
   "source": [
    "# Save PhoBERT and CNN\n",
    "\n",
    "torch.save(phoBert,'module2_part1.pt')\n",
    "torch.save(cnn,'module2_part2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoConfig, AutoTokenizer, PreTrainedModel\n",
    "\n",
    "# Tải PhoBERT và CNN đã lưu\n",
    "phoBert = torch.load('module2_part1.pt')\n",
    "cnn = torch.load('module2_part2.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhoBERTCNN(PreTrainedModel):\n",
    "    config_class = AutoConfig\n",
    "\n",
    "    def __init__(self, config, phoBert, cnn):\n",
    "        super().__init__(config)\n",
    "        self.phoBert = phoBert  # PhoBERT model\n",
    "        self.cnn = cnn          # CNN model\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        # Get PhoBERT outputs\n",
    "        phoBert_outputs = self.phoBert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = phoBert_outputs.last_hidden_state  # [batch size, seq len, hidden_dim]\n",
    "\n",
    "        # Pass through the CNN model\n",
    "        cnn_output = self.cnn(last_hidden_state)\n",
    "        return cnn_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo cấu hình PhoBERT\n",
    "config = AutoConfig.from_pretrained('vinai/phobert-base-v2')\n",
    "config.num_labels = 3  # Điều chỉnh theo số nhãn của bạn\n",
    "\n",
    "# Khởi tạo mô hình kết hợp\n",
    "combined_model = PhoBERTCNN(config, phoBert, cnn)\n",
    "\n",
    "# Lưu mô hình và tokenizer\n",
    "combined_model.save_pretrained(\"./PhoBERTCNN\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base-v2')\n",
    "tokenizer.save_pretrained(\"./PhoBERTCNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Tải lại mô hình và tokenizer\n",
    "loaded_model = CombinedPhoBERTCNN.from_pretrained(\"./PhoBERTCNN\")\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(\"./PhoBERTCNN\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "thaiduong",
   "language": "python",
   "name": "tdenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1697209912864e0884c53bc70eac7929": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c79c954408749abb907934a56b6995f",
       "IPY_MODEL_4b4c93c9fa0e42d0bfe5edf37716e5be",
       "IPY_MODEL_b0be66a7a999436292c18cab3eb88d9f"
      ],
      "layout": "IPY_MODEL_196ac666266f47b193ca577e4a5a4027"
     }
    },
    "196ac666266f47b193ca577e4a5a4027": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32c38b57c2d644ec895fd3bce126dd2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4078451a1ccc49e7a7cb0e3edcf8c7af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4b4c93c9fa0e42d0bfe5edf37716e5be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eeaeeab00bdc40dbad28ab45da8ef293",
      "max": 540322347,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4078451a1ccc49e7a7cb0e3edcf8c7af",
      "value": 540322347
     }
    },
    "51f9d11c02814521a70b6a2a3e1c5cf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c79c954408749abb907934a56b6995f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a120123a22d946d7ba07ce88964ba891",
      "placeholder": "​",
      "style": "IPY_MODEL_bff2bc27692e4434bb2418f26da44793",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "a120123a22d946d7ba07ce88964ba891": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0be66a7a999436292c18cab3eb88d9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32c38b57c2d644ec895fd3bce126dd2c",
      "placeholder": "​",
      "style": "IPY_MODEL_51f9d11c02814521a70b6a2a3e1c5cf6",
      "value": " 540M/540M [00:08&lt;00:00, 62.7MB/s]"
     }
    },
    "bff2bc27692e4434bb2418f26da44793": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eeaeeab00bdc40dbad28ab45da8ef293": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
